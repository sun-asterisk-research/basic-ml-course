{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaymondMartin/basic-ml-course/blob/master/Martin_Irungu_Solution_for_lesson_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 7: Neural Network\n"
      ],
      "metadata": {
        "id": "tlVq7ofl6xKT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: To run this notebook. You should change runtime type to GPU by: go to Runtime -> Change runtime type -> GPU"
      ],
      "metadata": {
        "id": "cSmwGOOG65cn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In lecture 7's video, we have shown you how to use Neural Network to classify handwritten digits on the MNIST dataset. In this notebook, we will go into the details. We also discover components that we have not talked about in the video."
      ],
      "metadata": {
        "id": "k5lcx-ax7HBz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpily/basic-ml-course/blob/Lecture_07/Solution7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTpe3i7baZQ0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.MNIST('./data', download=True, train=True, transform=transforms.ToTensor())\n",
        "testset = torchvision.datasets.MNIST('./data', download=True, train=False, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "oyE08v9PbOKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = trainset[20]\n",
        "print('Label: ', label)\n",
        "print('Image shape: ', img.shape)\n",
        "plt.imshow(img[0], cmap='gray')"
      ],
      "metadata": {
        "id": "Fd3DX8Q2bUO-",
        "outputId": "d9de9053-af7b-4c10-b8e5-26bb0b56c5ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:  4\n",
            "Image shape:  torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f31a5ed3340>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2, drop_last=True, pin_memory=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "g5grSGK9Wd4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_layer = nn.Linear(2, 4)           # we create a layer\n",
        "print(\"transposed weight: \", a_layer.weight.T)   # print the weight of the layer\n",
        "print(\"bias: \", a_layer.bias)       # print the bias of the layer\n",
        "input = torch.rand((3, 2))          # we create a dummy input\n",
        "print('input: ', input)\n",
        "# your code here      \n",
        "output = torch.matmul(input,a_layer.weight.T) + a_layer.bias\n",
        "print('output: ', output)"
      ],
      "metadata": {
        "id": "Z_3sDDVAWm-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3e9402-d2d6-40b0-cdac-b472fb2907d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transposed weight:  tensor([[-0.6097,  0.3334,  0.0676, -0.6246],\n",
            "        [-0.1401, -0.4020, -0.5802, -0.0434]], grad_fn=<PermuteBackward0>)\n",
            "bias:  Parameter containing:\n",
            "tensor([-0.3262, -0.6727,  0.1811,  0.6196], requires_grad=True)\n",
            "input:  tensor([[0.5011, 0.2752],\n",
            "        [0.0128, 0.0229],\n",
            "        [0.2415, 0.3615]])\n",
            "output:  tensor([[-0.6702, -0.6163,  0.0553,  0.2947],\n",
            "        [-0.3372, -0.6777,  0.1687,  0.6107],\n",
            "        [-0.5240, -0.7375, -0.0124,  0.4531]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 120)  # first hidden layer\n",
        "        self.fc2 = nn.Linear(120, 84)     # second hidden layer\n",
        "        # your code here\n",
        "        self.additional_layer = nn.Linear(84,84)\n",
        "        self.fc3 = nn.Linear(84, 10)      # output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)   # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))   # compute output of first hidden layer + activation function\n",
        "        x = F.relu(self.fc2(x))   # compute output of second hiddlen layer + activation function\n",
        "        # your code here\n",
        "        x = F.relu(self.additional_layer(x))\n",
        "        x = self.fc3(x)           # compute output\n",
        "        return x                  # return output\n",
        "\n",
        "model = Net()"
      ],
      "metadata": {
        "id": "sk_AZa0Zexey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "  #your code here\n",
        "  output = z.exp() / z.exp().sum(-1).unsqueeze(-1)\n",
        "  return output"
      ],
      "metadata": {
        "id": "peORtOwq7dlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(z):\n",
        "  return softmax(z).log()"
      ],
      "metadata": {
        "id": "UDySsb2Cfxos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def nll(preds, target):\n",
        "  \n",
        "  #initialize a prediction with zeros 0's with same shape with preds\n",
        "\n",
        "  shape_pred = torch.zeros(preds.shape)\n",
        "  for i in range(target.size()[0]):\n",
        "    shape_pred[i][target[i]] = 1\n",
        "\n",
        "  l = -preds * shape_pred\n",
        "  return l"
      ],
      "metadata": {
        "id": "6xN24j7WgE1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(z, target):\n",
        "  \n",
        "  return torch.sum(nll(log_softmax(z), target),axis=1).mean()\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "z = torch.rand((3, 10))\n",
        "\n",
        "target = torch.tensor([0, 5, 9], dtype=torch.long)\n",
        "print(\"cross_entropy_loss\",cross_entropy_loss(z, target))\n",
        "print(\"loss \",loss_function(z, target))\n",
        "\n",
        "assert cross_entropy_loss(z, target) == loss_function(z, target), 'The two above task are not correct!'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iFBapMXzJm1",
        "outputId": "84d1a63b-8d6a-4952-df0d-845d893baf58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cross_entropy_loss tensor(2.2027)\n",
            "loss  tensor(2.2027)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def CEloss_with_l2(z, target, model, alpha):\n",
        "  #initializing the first l1 CE loss\n",
        "  CE_loss = cross_entropy_loss(z, target)\n",
        "  # Your code here\n",
        "  L2_loss = 0\n",
        "  for param in model.parameters():\n",
        "    L2_loss +=  torch.sum(param ** 2)\n",
        "  loss = CE_loss + alpha * L2_loss\n",
        "  return loss\n",
        "\n",
        "CEloss_with_l2(torch.rand(2, 10), torch.tensor([2, 3], dtype=torch.long), model, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hRvqJiB7j53",
        "outputId": "08f842a0-16d3-4bab-d046-4f0fb4be8155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.5300, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def CEloss_with_l1(z, target, model, alpha):\n",
        "  # Your code here\n",
        "  CE_loss = cross_entropy_loss(z,target)\n",
        "  L1_loss = 0\n",
        "  for param in model.parameters():\n",
        "    L1_loss += torch.sum(torch.abs(param))\n",
        "  loss = CE_loss + alpha * L1_loss\n",
        "  return loss\n",
        "\n",
        "CEloss_with_l1(torch.rand(2, 10), torch.tensor([2, 3], dtype=torch.long), model, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fy4TFDMFmj7",
        "outputId": "db4d6012-407a-4bfd-a3df-1ab5295eb7fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.0449, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "7mIgOiCFGH5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()    # move model to GPU for faster computation in parallel\n",
        "n_epochs = 15    # you should change to larger value\n",
        "for epoch in range(n_epochs):\n",
        "  print(f'Epoch {epoch}- Training... ')\n",
        "  for batch_idx, (imgs, labels) in enumerate(tqdm(train_dataloader)):\n",
        "    imgs = imgs.cuda()      # move images to GPU\n",
        "    labels = labels.cuda()  # move labels to GPU\n",
        "    optimizer.zero_grad()   # by default, Pytorch's optimizer retains gradient after apply Gradient Descent. We need to call this function to clear gradients explicitly.\n",
        "    preds = model(imgs)     # pass batch of data through the model. \n",
        "    loss = loss_function(preds, labels)   # compute loss \n",
        "    loss.backward()         # compute gradient by running backpropgation algorithm\n",
        "    optimizer.step()        # apply Gradient Descent\n",
        "  \n",
        "  # evaluate \n",
        "  print(f'Epoch {epoch}- Evaluating... ')\n",
        "  total_correct = 0\n",
        "  total = len(testset)\n",
        "  for batch_indx, (imgs, labels) in enumerate(tqdm(test_dataloader)):\n",
        "    imgs = imgs.cuda()\n",
        "    labels = labels.cuda()\n",
        "    preds = model(imgs).argmax(axis=-1)\n",
        "    #loss = loss_function(preds, labels)\n",
        "    #loss.backward()\n",
        "    n_correct = torch.sum(preds == labels)\n",
        "    total_correct += n_correct.item()\n",
        "  \n",
        "  print(\"Accuracy: \", total_correct/total)\n"
      ],
      "metadata": {
        "id": "0HsjQ5js_4L7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a886487-bf91-413b-b2c0-2d9506d7ec3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 240.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 193.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8904\n",
            "Epoch 1- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 235.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 197.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.915\n",
            "Epoch 2- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:16<00:00, 227.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 198.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9479\n",
            "Epoch 3- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:16<00:00, 229.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 192.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9577\n",
            "Epoch 4- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 235.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 188.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9604\n",
            "Epoch 5- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:16<00:00, 231.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 195.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9653\n",
            "Epoch 6- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:16<00:00, 233.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 189.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9706\n",
            "Epoch 7- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 235.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 186.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9697\n",
            "Epoch 8- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 235.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 194.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9735\n",
            "Epoch 9- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 237.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 190.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9749\n",
            "Epoch 10- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 235.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 195.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9738\n",
            "Epoch 11- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:16<00:00, 232.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 193.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9755\n",
            "Epoch 12- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 235.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 195.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9742\n",
            "Epoch 13- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 238.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 191.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9729\n",
            "Epoch 14- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:16<00:00, 224.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 195.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = testset[4586]   # you can change the index\n",
        "# input_tensor = torch.tensor(img).cuda() # convert image to tensor to be able to pass through model, and model the image to GPU\n",
        "input_tensor = img.clone().detach().cuda()  # to remove the torch.tensor will be deprecated error we use x.clone()\n",
        "output = model(input_tensor)\n",
        "# your code here\n",
        "value = model(input_tensor).argmax(axis=-1)[0]\n",
        "confident_score = softmax(model(input_tensor))[0].max() * 100\n",
        "print(f\"Prediction: {value} - confident score: {confident_score}\")\n",
        "plt.imshow(img[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "BKc5aBeBIofx",
        "outputId": "58868234-6d95-4cf0-8630-b6e61bb463ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 3 - confident score: 98.72122192382812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f31a5a622e0>"
            ]
          },
          "metadata": {},
          "execution_count": 132
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = testset[1556]   # you can change the index\n",
        "# input_tensor = torch.tensor(img).cuda() # convert image to tensor to be able to pass through model, and model the image to GPU\n",
        "input_tensor = img.clone().detach().cuda()  # to remove the torch.tensor will be deprecated error we use x.clone()\n",
        "output = model(input_tensor)\n",
        "# your code here\n",
        "value = model(input_tensor).argmax(axis=-1)[0]\n",
        "confident_score = softmax(model(input_tensor))[0].max() * 100\n",
        "print(f\"Prediction: {value} - confident score: {confident_score}\")\n",
        "plt.imshow(img[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "DH5wcg_QPFgM",
        "outputId": "f3677c3e-2a42-46cb-f909-e11af3a3c664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 8 - confident score: 99.99990844726562\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f319b7fa490>"
            ]
          },
          "metadata": {},
          "execution_count": 138
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = testset[167]   # you can change the index\n",
        "# input_tensor = torch.tensor(img).cuda() # convert image to tensor to be able to pass through model, and model the image to GPU\n",
        "input_tensor = img.clone().detach().cuda()  # to remove the torch.tensor will be deprecated error we use x.clone()\n",
        "output = model(input_tensor)\n",
        "# your code here\n",
        "value = model(input_tensor).argmax(axis=-1)[0]\n",
        "confident_score = softmax(model(input_tensor))[0].max() * 100\n",
        "print(f\"Prediction: {value} - confident score: {confident_score}\")\n",
        "plt.imshow(img[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "h5WBR2G_QQHF",
        "outputId": "fb5b5bc5-e9f0-4bd6-b693-15984c8ff69b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 5 - confident score: 99.38446044921875\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f319b6f1d60>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BgQakLryQSuc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}