{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njauflo/basic-ml-course/blob/Week7/Solution_7_Neural%20Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 7: Neural Network"
      ],
      "metadata": {
        "id": "tepFZ8MaX6RR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: To run this notebook. You should change runtime type to GPU by: go to Runtime -> Change runtime type -> GPU"
      ],
      "metadata": {
        "id": "RWPSbcDu3Ef2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In lecture 7's video, we have shown you how to use Neural Network to classify handwritten digits on the MNIST dataset. In this notebook, we will go into the details. We also discover components that we have not talked about in the video."
      ],
      "metadata": {
        "id": "vyE5Obn6PGvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import some libraries and packages"
      ],
      "metadata": {
        "id": "wUrX5_l-X9KH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "4tB_dVjrC3b1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download dataset"
      ],
      "metadata": {
        "id": "L7zxH2HHYNI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.MNIST('./data', download=True, train=True, transform=transforms.ToTensor())\n",
        "testset = torchvision.datasets.MNIST('./data', download=True, train=False, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "73RIk4mSC-Jn"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check an image and its label"
      ],
      "metadata": {
        "id": "f5404CDSZotp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = trainset[20]\n",
        "print('Label: ', label)\n",
        "print('Image shape: ', img.shape)\n",
        "plt.imshow(img[0], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "DLqfRHE7FVnF",
        "outputId": "68d545a7-e967-4936-de93-0193087d3a9a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:  4\n",
            "Image shape:  torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff7704fef10>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch provides DataLoader to efficiently load data from dataset for both training and testing. For more details about the configurations, you can refer to https://pytorch.org/docs/stable/data.html"
      ],
      "metadata": {
        "id": "YxJduKT8fZ1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2, drop_last=True, pin_memory=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "93XeSyr-G_si"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An Neural Network has layers. To create a layer you can use `nn.Linear`. Let examine one layer.\n",
        "\n",
        "Here we create a layer which has 4 neurons and 2 inputs. Matrix of weight ($W$) has shape of 4x2, $W \\in \\mathbb{R}^{4*2}$. The bias vector of neurons is b, $b \\in \\mathbb{R}^{4}$. Assuming the input $x \\in \\mathbb{R}^{b*2}$, where is the batch size. Then the output of this layer is:\n",
        "$$ y = xW^T + b$$"
      ],
      "metadata": {
        "id": "qkmzheLN2Jmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1**: Fill in the code to calculate the output of a layer for given input. **(1 point)**\n",
        "\n",
        "*Hints*: for matrix multiplication in pytorch, you can use `torch.matmul`. "
      ],
      "metadata": {
        "id": "29LWl7tGJA1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_layer = nn.Linear(2, 4)           # we create a layer\n",
        "print(\"transposed weight: \", a_layer.weight.T)   # print the weight of the layer\n",
        "print(\"bias: \", a_layer.bias)       # print the bias of the layer\n",
        "input = torch.rand((3, 2))          # we create a dummy input\n",
        "print('input: ', input)\n",
        "# your code here     \n",
        "output = torch.matmul(input, a_layer.weight.T) + a_layer.bias\n",
        "print('output: ', output)          "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_9wm9qblzjw",
        "outputId": "f1a06f66-b82f-49bf-f50b-b6ef4c131d10"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transposed weight:  tensor([[-0.5809,  0.5786,  0.1344, -0.5720],\n",
            "        [ 0.0136, -0.6420, -0.4451, -0.6869]], grad_fn=<PermuteBackward0>)\n",
            "bias:  Parameter containing:\n",
            "tensor([0.3530, 0.6198, 0.4723, 0.3315], requires_grad=True)\n",
            "input:  tensor([[0.2594, 0.7981],\n",
            "        [0.6086, 0.6180],\n",
            "        [0.6526, 0.3181]])\n",
            "output:  tensor([[ 0.2132,  0.2576,  0.1519, -0.3651],\n",
            "        [ 0.0079,  0.5752,  0.2790, -0.4411],\n",
            "        [-0.0217,  0.7932,  0.4184, -0.2603]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2**: We implement below architecture in the video. It works quite well. Let's try to add the third hidden layer and keep other layers. **(1 point)**"
      ],
      "metadata": {
        "id": "KC783pMOJ7Md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 120)  # first hidden layer\n",
        "        self.fc2 = nn.Linear(120, 84)     # second hidden layer\n",
        "        self.additional_layer = nn.Linear (84, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)      # output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)   # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))   # compute output of first hidden layer + activation function\n",
        "        x = F.relu(self.fc2(x))   # compute output of second hiddlen layer + activation function\n",
        "        # your code here\n",
        "        x = F.relu(self.additional_layer(x))\n",
        "        x = self.fc3(x)           # compute output\n",
        "        return x                  # return output\n",
        "\n",
        "model = Net()"
      ],
      "metadata": {
        "id": "Qlc38zzsVsGZ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used `CrossEntropyLoss` function to calculate loss. It is equivalent to the combination of `LogSoftmax` and `NLLLoss`. We have not talked about these two functions. They are two commonly used functions in classification problems.\n",
        "\n",
        "In the output layer, we don't use any activation function. To get the final prediction, we just need to chooose the maximum output. However, you should use softmax to get the estimated probabilities. Output of softmax function are:\n",
        "\n",
        "\n",
        "<center>$\\sigma(z)_{i} = \\frac{e^{z_{i}}}{\\sum_{j=1}^{C}e^{z_{j}}} $ for $i = 1, ..., C$ and $\\textbf{z} = \\{z_1, z_2, ..., z_C\\}$</center>\n",
        "\n",
        "\n",
        "where $C$ is number of classes, $\\textbf{z}$ is the output of network."
      ],
      "metadata": {
        "id": "t0kmvQFBl7Ea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3**: You are asked to implement softmax function **(1 point)**\n",
        "\n",
        "Hints: to calculate the exponential of input elements you can use *exp()* function. For example, `z.exp()`"
      ],
      "metadata": {
        "id": "raYd3kbv255I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "  # your code here\n",
        "  output = z.exp() / z.exp().sum(-1).unsqueeze(-1)\n",
        "  return output"
      ],
      "metadata": {
        "id": "eA9waX0s2pXd"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(z):\n",
        "  return softmax(z).log()"
      ],
      "metadata": {
        "id": "1pMnBoYC_77I"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 4**: You are asked to implement Negative Log Likelihood as follow: **(1 point)**\n",
        "<center>$l_n = -x_n y_n$ where $\\textbf{x}$ is prediction, $\\textbf{y}$ is target in form of one-hot vector, </center> \n",
        "\n",
        "Note: in above equation $\\textbf{y}$ is an one-hot vector. Meanwhile, the below `target` is an integer value."
      ],
      "metadata": {
        "id": "cFr4H-ov7ELW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nll(preds, target):\n",
        "  # your code here\n",
        "  shape_pred = torch.zeros_like(preds)\n",
        "  for i, pred in enumerate(target):\n",
        "    shape_pred[i][pred] = 1\n",
        "\n",
        "    l = -preds * shape_pred\n",
        "  return l"
      ],
      "metadata": {
        "id": "zZzvfRPw7MUr"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(z, target):\n",
        "  return nll(log_softmax(z), target).mean()\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "z = torch.rand((3, 10))\n",
        "target = torch.tensor([0, 5, 9], dtype=torch.long)\n",
        "print('cross_entropy_loss',cross_entropy_loss(z, target))\n",
        "print('Loss',loss_function(z, target))\n",
        "\n",
        "# assert cross_entropy_loss(z, target) == loss_function(z, target), 'The two above task are not correct!'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_eIAavpBRPs",
        "outputId": "dd39a12f-5348-4251-b345-51b8fed02f82"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cross_entropy_loss tensor(0.2473)\n",
            "Loss tensor(2.4733)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We constraint the model not too complex by using regularization. One way of doing that is putting constraint to weights of models. For example, in ridge regularization, we add L2 loss term to the loss function:\n",
        "$$J(\\theta) = CrossEntropyLoss(\\theta) + \\alpha \\sum\\limits_{i=1}^n\\theta_{i}^2$$\n",
        "where $\\theta$ is model's parameters (not including bias), $\\alpha$ is a hyper-paramter to control degree of regularization."
      ],
      "metadata": {
        "id": "dR_xYpSNOpNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 5**: You are asked to implement loss function composed of cross entropy loss and L2 regularization loss. **(1 point)**\n",
        "\n",
        "Hints: use `model.parameters()`"
      ],
      "metadata": {
        "id": "ThudlUyGrgfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CEloss_with_l2(z, target, model, alpha):\n",
        "  CE_loss = cross_entropy_loss(z, target)\n",
        "  # Your code here\n",
        "  L2_loss = 0\n",
        "  for param in model.parameters():\n",
        "    L2_loss +=  torch.sum(param ** 2)\n",
        "  loss = CE_loss + alpha * L2_loss\n",
        "  return loss\n",
        "\n",
        "CEloss_with_l2(torch.rand(2, 10), torch.tensor([2, 3], dtype=torch.long), model, 0.001)"
      ],
      "metadata": {
        "id": "nv6SMrKOOnDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae01f58-d58a-4b78-fb3f-c83db00b1266"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3475, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 6**: Similarly, let implement loss function composed of cross entropy loss and L1 regularization **(1 point)**"
      ],
      "metadata": {
        "id": "mKq31_We09al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CEloss_with_l1(z, target, model, alpha):\n",
        "  # Your code here\n",
        " CE_loss = cross_entropy_loss(z,target)\n",
        " l1_loss = 0\n",
        " for param in model.parameters():\n",
        "    l1_loss += torch.sum(torch.abs(param))\n",
        " loss = CE_loss + alpha * l1_loss\n",
        " return loss\n",
        "\n",
        "CEloss_with_l1(torch.rand(2, 10), torch.tensor([2, 3], dtype=torch.long), model, 0.001)"
      ],
      "metadata": {
        "id": "npqOPHEB1KuM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "216f9488-2319-4db8-c54a-7c4bb85f58e1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.8464, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For using L2 regularization in Pytorch, you can set `weight_decay` property of optimizer. Here, we use the default value `weight_decay=0`."
      ],
      "metadata": {
        "id": "Avtue18G2ExY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "8gNz2v3xIBLx"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 7:** Below code is the procedure to train and evaluate the trained model. We put more comments so you can better understand each line of code. We also put redundant lines of code in the `evaluate` section. Your task is to find all redundant code and comment them out. (**2 points**)"
      ],
      "metadata": {
        "id": "8pAgHxZJVyH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()    # move model to GPU for faster computation in parallel\n",
        "n_epochs = 5   # you should change to larger value\n",
        "for epoch in range(n_epochs):\n",
        "  print(f'Epoch {epoch}- Training... ')\n",
        "  for batch_idx, (imgs, labels) in enumerate(tqdm(train_dataloader)):\n",
        "    imgs = imgs.cuda()      # move images to GPU\n",
        "    labels = labels.cuda()  # move labels to GPU\n",
        "    optimizer.zero_grad()   # by default, Pytorch's optimizer retains gradient after apply Gradient Descent. We need to call this function to clear gradients explicitly.\n",
        "    preds = model(imgs)     # pass batch of data through the model. \n",
        "    loss = loss_function(preds, labels)   # compute loss \n",
        "    loss.backward()         # compute gradient by running backpropgation algorithm\n",
        "    optimizer.step()        # apply Gradient Descent\n",
        "  \n",
        "  # evaluate \n",
        "  print(f'Epoch {epoch}- Evaluating... ')\n",
        "  total_correct = 0\n",
        "  total = len(testset)\n",
        "  for batch_indx, (imgs, labels) in enumerate(tqdm(test_dataloader)):\n",
        "    imgs = imgs.cuda()\n",
        "    labels = labels.cuda()\n",
        "    preds = model(imgs).argmax(axis=-1)\n",
        "    #loss = loss_function(preds, labels)\n",
        "    #loss.backward()\n",
        "    n_correct = torch.sum(preds == labels)\n",
        "    total_correct += n_correct.item()\n",
        "  \n",
        "  print(\"Accuracy: \", total_correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY4UMUc2WTZA",
        "outputId": "e0b5b7db-6ef3-4a05-b491-9510655bff27"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 236.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 198.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9041\n",
            "Epoch 1- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 238.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 197.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9296\n",
            "Epoch 2- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:16<00:00, 229.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 201.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9406\n",
            "Epoch 3- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 238.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 201.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9557\n",
            "Epoch 4- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:16<00:00, 234.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:02<00:00, 127.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 8**: In this task, you are asked to use the last trained model to make a prediction of an image on test set. You also need to calculate the confident score of that prediction using softmax function. **(2 points)**"
      ],
      "metadata": {
        "id": "nTMfYOwhQaL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = testset[0]   # you can change the index\n",
        "input_tensor = torch.tensor(img).cuda()   # convert image to tensor to be able to pass through model, and model the image to GPU\n",
        "output = model(input_tensor)\n",
        "# your code here\n",
        "value = model(input_tensor).argmax(axis=-1)[0]\n",
        "confident_score = softmax(model(input_tensor))[0].max() * 100\n",
        "print(f\"Prediction: {value} - confident score: {confident_score}\")\n",
        "plt.imshow(img[0])"
      ],
      "metadata": {
        "id": "cIHAOO6Tfq9i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "52bb3458-680e-4476-c281-a2b36f92c629"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-2c74712a8e11>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_tensor = torch.tensor(img).cuda()   # convert image to tensor to be able to pass through model, and model the image to GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 7 - confident score: 99.4376220703125\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff77032f160>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}