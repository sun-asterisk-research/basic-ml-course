{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MUTTA-ISIGI/basic-ml-course/blob/week7/Lecture_7_homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 7: Neural Network"
      ],
      "metadata": {
        "id": "tepFZ8MaX6RR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: To run this notebook. You should change runtime type to GPU by: go to Runtime -> Change runtime type -> GPU"
      ],
      "metadata": {
        "id": "RWPSbcDu3Ef2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In lecture 7's video, we have shown you how to use Neural Network to classify handwritten digits on the MNIST dataset. In this notebook, we will go into the details. We also discover components that we have not talked about in the video."
      ],
      "metadata": {
        "id": "vyE5Obn6PGvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import some libraries and packages"
      ],
      "metadata": {
        "id": "wUrX5_l-X9KH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4tB_dVjrC3b1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download dataset"
      ],
      "metadata": {
        "id": "L7zxH2HHYNI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.MNIST('./data', download=True, train=True, transform=transforms.ToTensor())\n",
        "testset = torchvision.datasets.MNIST('./data', download=True, train=False, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "73RIk4mSC-Jn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check an image and its label"
      ],
      "metadata": {
        "id": "f5404CDSZotp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = trainset[20]\n",
        "print('Label: ', label)\n",
        "print('Image shape: ', img.shape)\n",
        "plt.imshow(img[0], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "DLqfRHE7FVnF",
        "outputId": "b6f8a7fc-8636-402c-bac9-47c40e8ad5f6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:  4\n",
            "Image shape:  torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f46a8549670>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch provides DataLoader to efficiently load data from dataset for both training and testing. For more details about the configurations, you can refer to https://pytorch.org/docs/stable/data.html"
      ],
      "metadata": {
        "id": "YxJduKT8fZ1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2, drop_last=True, pin_memory=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "93XeSyr-G_si"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An Neural Network has layers. To create a layer you can use `nn.Linear`. Let examine one layer.\n",
        "\n",
        "Here we create a layer which has 4 neurons and 2 inputs. Matrix of weight ($W$) has shape of 4x2, $W \\in \\mathbb{R}^{4*2}$. The bias vector of neurons is b, $b \\in \\mathbb{R}^{4}$. Assuming the input $x \\in \\mathbb{R}^{b*2}$, where is the batch size. Then the output of this layer is:\n",
        "$$ y = xW^T + b$$"
      ],
      "metadata": {
        "id": "qkmzheLN2Jmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1**: Fill in the code to calculate the output of a layer for given input. **(1 point)**\n",
        "\n",
        "*Hints*: for matrix multiplication in pytorch, you can use `torch.matmul`. "
      ],
      "metadata": {
        "id": "29LWl7tGJA1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_layer = nn.Linear(2, 4)           # we create a layer\n",
        "print(\"transposed weight: \", a_layer.weight.T)   # print the weight of the layer\n",
        "print(\"bias: \", a_layer.bias)       # print the bias of the layer\n",
        "input = torch.rand((3, 2))          # we create a dummy input\n",
        "print('input: ', input)\n",
        "# your code here      \n",
        "output = torch.matmul(input,a_layer.weight.T) + a_layer.bias  \n",
        "print('output: ', output)          "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_9wm9qblzjw",
        "outputId": "2b387917-faf1-45bf-8e6f-0d07e2f95313"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transposed weight:  tensor([[ 0.5169,  0.2431, -0.3284,  0.0759],\n",
            "        [ 0.6366,  0.0088,  0.5739, -0.0514]], grad_fn=<PermuteBackward0>)\n",
            "bias:  Parameter containing:\n",
            "tensor([0.4494, 0.0237, 0.3430, 0.0590], requires_grad=True)\n",
            "input:  tensor([[0.8187, 0.5134],\n",
            "        [0.8609, 0.3208],\n",
            "        [0.9887, 0.0354]])\n",
            "output:  tensor([[1.1995, 0.2272, 0.3688, 0.0948],\n",
            "        [1.0986, 0.2358, 0.2443, 0.1079],\n",
            "        [0.9830, 0.2643, 0.0386, 0.1323]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2**: We implement below architecture in the video. It works quite well. Let's try to add the third hidden layer and keep other layers. **(1 point)**"
      ],
      "metadata": {
        "id": "KC783pMOJ7Md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 120)  # first hidden layer\n",
        "        self.fc2 = nn.Linear(120, 84)     # second hidden layer\n",
        "        # your code here\n",
        "        self.additional_layer = nn.Linear(84,84)\n",
        "        self.fc3 = nn.Linear(84, 10)      # output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)   # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))   # compute output of first hidden layer + activation function\n",
        "        x = F.relu(self.fc2(x))   # compute output of second hiddlen layer + activation function\n",
        "        # your code here\n",
        "        x = F.relu(self.additional_layer(x))\n",
        "        x = self.fc3(x)           # compute output\n",
        "        return x                  # return output\n",
        "\n",
        "model = Net()"
      ],
      "metadata": {
        "id": "Qlc38zzsVsGZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used `CrossEntropyLoss` function to calculate loss. It is equivalent to the combination of `LogSoftmax` and `NLLLoss`. We have not talked about these two functions. They are two commonly used functions in classification problems.\n",
        "\n",
        "In the output layer, we don't use any activation function. To get the final prediction, we just need to chooose the maximum output. However, you should use softmax to get the estimated probabilities. Output of softmax function are:\n",
        "\n",
        "\n",
        "<center>$\\sigma(z)_{i} = \\frac{e^{z_{i}}}{\\sum_{j=1}^{C}e^{z_{j}}} $ for $i = 1, ..., C$ and $\\textbf{z} = \\{z_1, z_2, ..., z_C\\}$</center>\n",
        "\n",
        "\n",
        "where $C$ is number of classes, $\\textbf{z}$ is the output of network."
      ],
      "metadata": {
        "id": "t0kmvQFBl7Ea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3**: You are asked to implement softmax function **(1 point)**\n",
        "\n",
        "Hints: to calculate the exponential of input elements you can use *exp()* function. For example, `z.exp()`"
      ],
      "metadata": {
        "id": "raYd3kbv255I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "  # your code here\n",
        "  output = z.exp() / z.exp().sum(-1).unsqueeze(-1)\n",
        "  return output"
      ],
      "metadata": {
        "id": "eA9waX0s2pXd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(z):\n",
        "  return softmax(z).log()"
      ],
      "metadata": {
        "id": "1pMnBoYC_77I"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 4**: You are asked to implement Negative Log Likelihood as follow: **(1 point)**\n",
        "<center>$l_n = -x_n y_n$ where $\\textbf{x}$ is prediction, $\\textbf{y}$ is target in form of one-hot vector, </center> \n",
        "\n",
        "Note: in above equation $\\textbf{y}$ is an one-hot vector. Meanwhile, the below `target` is an integer value."
      ],
      "metadata": {
        "id": "cFr4H-ov7ELW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nll(preds, target):\n",
        "  # your code here\n",
        "  l = shape_pred = torch.zeros_like(preds)\n",
        "  for i in range(target.size()[0]):\n",
        "    shape_pred[i][target[i]] = 1\n",
        "\n",
        "  l = -preds * shape_pred\n",
        "  \n",
        "  return l"
      ],
      "metadata": {
        "id": "zZzvfRPw7MUr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(z, target):\n",
        "  return nll(log_softmax(z), target).mean()\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "z = torch.rand((3, 10))\n",
        "target = torch.tensor([0, 5, 9], dtype=torch.long)\n",
        "print(cross_entropy_loss(z, target))\n",
        "print(loss_function(z, target))\n",
        "\n",
        "# assert cross_entropy_loss(z, target) == loss_function(z, target), 'The two above task are not correct!'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_eIAavpBRPs",
        "outputId": "26632241-d49e-4f60-d653-c641d792fc22"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2225)\n",
            "tensor(2.2251)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We constraint the model not too complex by using regularization. One way of doing that is putting constraint to weights of models. For example, in ridge regularization, we add L2 loss term to the loss function:\n",
        "$$J(\\theta) = CrossEntropyLoss(\\theta) + \\alpha \\sum\\limits_{i=1}^n\\theta_{i}^2$$\n",
        "where $\\theta$ is model's parameters (not including bias), $\\alpha$ is a hyper-paramter to control degree of regularization."
      ],
      "metadata": {
        "id": "dR_xYpSNOpNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 5**: You are asked to implement loss function composed of cross entropy loss and L2 regularization loss. **(1 point)**\n",
        "\n",
        "Hints: use `model.parameters()`"
      ],
      "metadata": {
        "id": "ThudlUyGrgfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CEloss_with_l2(z, target, model, alpha):\n",
        "  CE_loss = cross_entropy_loss(z, target)\n",
        "  # Your code here\n",
        "  L2_loss = 0\n",
        "  for param in model.parameters():\n",
        "    L2_loss +=  torch.sum(param ** 2)\n",
        "  loss = CE_loss + alpha * L2_loss\n",
        "\n",
        "\n",
        "  return loss\n",
        "\n",
        "CEloss_with_l2(torch.rand(2, 10), torch.tensor([2, 3], dtype=torch.long), model, 0.001)"
      ],
      "metadata": {
        "id": "nv6SMrKOOnDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bdd017b-784c-4f13-ba0f-ff9ae6af049e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3149, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 6**: Similarly, let implement loss function composed of cross entropy loss and L1 regularization **(1 point)**"
      ],
      "metadata": {
        "id": "mKq31_We09al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CEloss_with_l1(z, target, model, alpha):\n",
        "  # Your code here\n",
        "  CE_loss = cross_entropy_loss(z,target)\n",
        "  L1_loss = 0\n",
        "  for param in model.parameters():\n",
        "    L1_loss += torch.sum(torch.abs(param))\n",
        "  loss = CE_loss + alpha * L1_loss\n",
        "  return loss\n",
        "\n",
        "CEloss_with_l1(torch.rand(2, 10), torch.tensor([2, 3], dtype=torch.long), model, 0.001)"
      ],
      "metadata": {
        "id": "npqOPHEB1KuM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab7ea50-b8bb-421c-ec8e-882fc2031223"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.8102, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For using L2 regularization in Pytorch, you can set `weight_decay` property of optimizer. Here, we use the default value `weight_decay=0`."
      ],
      "metadata": {
        "id": "Avtue18G2ExY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "8gNz2v3xIBLx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Okhy-yQhQOXb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 7:** Below code is the procedure to train and evaluate the trained model. We put more comments so you can better understand each line of code. We also put redundant lines of code in the `evaluate` section. Your task is to find all redundant code and comment them out. (**2 points**)"
      ],
      "metadata": {
        "id": "8pAgHxZJVyH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()    # move model to GPU for faster computation in parallel\n",
        "n_epochs = 10    # you should change to larger value\n",
        "for epoch in range(n_epochs):\n",
        "  print(f'Epoch {epoch}- Training... ')\n",
        "  for batch_idx, (imgs, labels) in enumerate(tqdm(train_dataloader)):\n",
        "    imgs = imgs.cuda()      # move images to GPU\n",
        "    labels = labels.cuda()  # move labels to GPU\n",
        "    optimizer.zero_grad()   # by default, Pytorch's optimizer retains gradient after apply Gradient Descent. We need to call this function to clear gradients explicitly.\n",
        "    preds = model(imgs)     # pass batch of data through the model. \n",
        "    loss = loss_function(preds, labels)   # compute loss \n",
        "    loss.backward()         # compute gradient by running backpropgation algorithm\n",
        "    optimizer.step()        # apply Gradient Descent\n",
        "  \n",
        "  # evaluate \n",
        "  print(f'Epoch {epoch}- Evaluating... ')\n",
        "  total_correct = 0\n",
        "  total = len(testset)\n",
        "  for batch_indx, (imgs, labels) in enumerate(tqdm(test_dataloader)):\n",
        "    imgs = imgs.cuda()\n",
        "    labels = labels.cuda()\n",
        "    preds = model(imgs).argmax(axis=-1)\n",
        "    #loss = loss_function(preds, labels)\n",
        "    #loss.backward()\n",
        "    n_correct = torch.sum(preds == labels)\n",
        "    total_correct += n_correct.item()\n",
        "  \n",
        "  print(\"Accuracy: \", total_correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY4UMUc2WTZA",
        "outputId": "47f25601-0fb1-46af-eba6-c62dbb36cfc7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 239.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 201.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9763\n",
            "Epoch 1- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 236.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 196.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9755\n",
            "Epoch 2- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:16<00:00, 230.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 199.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9728\n",
            "Epoch 3- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 240.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 198.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9758\n",
            "Epoch 4- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 240.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 199.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9777\n",
            "Epoch 5- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 240.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 201.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9763\n",
            "Epoch 6- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 238.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 200.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9755\n",
            "Epoch 7- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:17<00:00, 215.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 197.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9681\n",
            "Epoch 8- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:16<00:00, 230.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 200.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9752\n",
            "Epoch 9- Training... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3750/3750 [00:15<00:00, 237.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9- Evaluating... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:01<00:00, 198.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 8**: In this task, you are asked to use the last trained model to make a prediction of an image on test set. You also need to calculate the confident score of that prediction using softmax function. **(2 points)**"
      ],
      "metadata": {
        "id": "nTMfYOwhQaL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = testset[0]   # you can change the index\n",
        "# input_tensor = torch.tensor(img).cuda() # convert image to tensor to be able to pass through model, and model the image to GPU\n",
        "input_tensor = img.clone().detach().cuda()  # to remove the torch.tensor will be deprecated error we use x.clone()\n",
        "output = model(input_tensor)\n",
        "# your code here\n",
        "value = model(input_tensor).argmax(axis=-1)[0]\n",
        "confident_score = softmax(model(input_tensor))[0].max() * 100\n",
        "print(f\"Prediction: {value} - confident score: {confident_score}\")\n",
        "plt.imshow(img[0])\n",
        "     \n"
      ],
      "metadata": {
        "id": "cIHAOO6Tfq9i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "3a0605d6-4c16-4801-bf0a-da6f5d42a1d8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 7 - confident score: 99.99911499023438\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f46a842d190>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = testset[1256]   # you can change the index\n",
        "# input_tensor = torch.tensor(img).cuda() # convert image to tensor to be able to pass through model, and model the image to GPU\n",
        "input_tensor = img.clone().detach().cuda()  # to remove the torch.tensor will be deprecated error we use x.clone()\n",
        "output = model(input_tensor)\n",
        "# your code here\n",
        "value = model(input_tensor).argmax(axis=-1)[0]\n",
        "confident_score = softmax(model(input_tensor))[0].max() * 100\n",
        "print(f\"Prediction: {value} - confident score: {confident_score}\")\n",
        "plt.imshow(img[0])\n",
        "     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "uxVBYEE-Tn_b",
        "outputId": "c9efa17c-4495-4fe1-eac9-515d3d8071b6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 2 - confident score: 99.39154052734375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f46a83413d0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = testset[100]   # you can change the index\n",
        "# input_tensor = torch.tensor(img).cuda() # convert image to tensor to be able to pass through model, and model the image to GPU\n",
        "input_tensor = img.clone().detach().cuda()  # to remove the torch.tensor will be deprecated error we use x.clone()\n",
        "output = model(input_tensor)\n",
        "# your code here\n",
        "value = model(input_tensor).argmax(axis=-1)[0]\n",
        "confident_score = softmax(model(input_tensor))[0].max() * 100\n",
        "print(f\"Prediction: {value} - confident score: {confident_score}\")\n",
        "plt.imshow(img[0])\n",
        "     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "_RLfleWUT4G2",
        "outputId": "7179077a-5849-47cd-9145-05835b69cb22"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 6 - confident score: 99.99952697753906\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f46a820cf10>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}